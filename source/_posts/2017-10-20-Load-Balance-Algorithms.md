---
title: Load Balance Algorithms
toc: true
date: 2017-10-20 20:39:07
tags: 
- Load Balance
categories:
- Algorithm
---

负载均衡算法是在系统做负载均衡时保证请求分配平衡合理的算法。

简言之，负载均衡算法决定了实际请求在到达系统时将会被转发至哪台机器进行处理。

下图就是一个负载均衡的示意图， module-A即为整个系统的负载均衡服务器（Load Balancer）。

![Load Balance 1](/images/algorithm/loadbalance1.png)

<!-- more -->

<br/>

常见的负载均衡算法一般分为以下几种：随机（Random）、轮训（Round Robin）、加权轮询（Weighted Round Robin)、最小连接数（Least Connections）、源地址哈希法（Source Hashing）和主备（Master-Slave）。

### 随机（Random）

顾名思义， 随机法就是随机选择一台后端服务器进行请求的处理。

可以通过编写不同出现概率权重的随机数函数来控制每台机器被分派的请求数量，从而控制各台机器的负载。

<br/>

### 轮询（Round Robin）

轮询法是指负载均衡服务器将客户端请求按顺序轮流分配到后端服务器上，以达到负载均衡的目的。 

比如我们现在有三台后端服务器，分别为服务器1、2、3。那么接下来到来的请求将会以  1-2-3-1-2-3-... 的顺序被依次分发至指定的服务器。

<br/>

### 加权轮询（Weighted Round Robin)

加权轮询法是普通轮询的提升版，它将请求顺序且按照权重分派到后端服务器。

比如我们现在有三台后端服务器，分别为服务器1、2、3， 其对应的权重分别为3、2、1。那么接下来的请求将会以 1-1-1-2-2-3-1-1-1-2-2-3-...  的顺序被依次分发至制定的服务器。

加权轮询法也极为容易实现。

<br/>

### 最小连接数（Least Connections）

即使后端机器的性能和负载一样，不同客户端请求复杂度不一样导致处理时间也不一样。

最小连接数法根据后端服务器当前的连接数情况，动态地选取其中积压连接数最小的一台服务器来处理当前的请求，尽可能提高后端服务器的利用效率，合理地将请求分流到每一台服务器。 

 一种简易的实现如下：

1. 统计所有服务器的连接数C(Si), 完成从C(S1)到C(Sn)的升序排序，形成最小连接表，然后开始监听请求
2. 当网络中监听到新的请求时，把该请求分发给表中最靠前的服务器处理，然后将相应的连接数C(Si)加1，然后重新维护最小连接表的顺序
3. 继续监听请求，重复step 2

但是这种方法在各个服务器性能不一致的情况下效果并不好。此时可以考虑结合服务器性能对算法进行改进。

<br/>

### 源地址哈希（Source Hashing）

源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。 

如果后端服务器是一缓存系统，当后端服务器增加或者减少时，采用简单的哈希取模的方法，会使得命中率大大降低，这个问题可以采用一致性哈希的方法来解决。 

详见一致性哈希算法。

<br/>

### 主备（Master-Slave）

主备方法将请求尽量的放到某个固定机器的服务上（注意这里是尽量），而其他机器的服务则用来做备份，如果出现问题就切换到另外的某台机器的服务上。

这个算法用的相对不是很多，只是在一些特殊情况下会使用这个算法。比如，我有多台Message Queue的服务，为了保证提交数据的时序性，我就想把所有的请求都尽量放到某台固定的服务上，当这台服务出现问题，再用其他的服务。

一种最简单的实现就是对每台机器的IP：Port做一个hash，然后按从大到小的顺序排序，第一个就是主服务器。如果第一个出现问题，那我们再取第二个服务器（备）：head(sort(hash("IP:Port1"), hash("IP:Port2"), ……))

<br/>
